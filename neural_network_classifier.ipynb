{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Input\n",
    "from tcn import TCN\n",
    "\n",
    "import preprocessing\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Flatten, SpatialDropout1D, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate\n",
    "from keras.layers.embeddings import Embedding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0  score                                             review\n0        591851    4.0  A short, but interesting book that reads fast....\n1         74509    1.0  Absolutely ridiculous. Should be listed under ...\n2        675572    5.0  The Deluge, the sacond of Henryk Sienkiewicz's...\n3        465431    4.0  This story should be included in any library o...\n4        505588    4.0  I have read \"Of Mice and Men\" by John Steinbec...\n..          ...    ...                                                ...\n995       62874    1.0  I always finish the books I read, because I am...\n996      452993    3.0  I read this book last year and thought it was ...\n997      696374    5.0  This book is a must have if you were a fan of ...\n998      322779    3.0  I have just put down Rita Ciresi's Pink Slip, ...\n999      132687    1.0  I tolerated the first book because I needed to...\n\n[1000 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>score</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>591851</td>\n      <td>4.0</td>\n      <td>A short, but interesting book that reads fast....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>74509</td>\n      <td>1.0</td>\n      <td>Absolutely ridiculous. Should be listed under ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>675572</td>\n      <td>5.0</td>\n      <td>The Deluge, the sacond of Henryk Sienkiewicz's...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>465431</td>\n      <td>4.0</td>\n      <td>This story should be included in any library o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>505588</td>\n      <td>4.0</td>\n      <td>I have read \"Of Mice and Men\" by John Steinbec...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>62874</td>\n      <td>1.0</td>\n      <td>I always finish the books I read, because I am...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>452993</td>\n      <td>3.0</td>\n      <td>I read this book last year and thought it was ...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>696374</td>\n      <td>5.0</td>\n      <td>This book is a must have if you were a fan of ...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>322779</td>\n      <td>3.0</td>\n      <td>I have just put down Rita Ciresi's Pink Slip, ...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>132687</td>\n      <td>1.0</td>\n      <td>I tolerated the first book because I needed to...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data = preprocessing.load_books_rating_data(1000)\n",
    "books_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot: xlabel='score', ylabel='count'>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"score\", data=books_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X_balanced, y_balanced = preprocessing.under_sample(np.array(books_data.text).reshape(-1, 1), books_data.score)\n",
    "X_balanced = [sent[0] for sent in X_balanced]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot: xlabel='score', ylabel='count'>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"score\", data=pd.DataFrame(y_balanced))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_tokenized = preprocessing.tokenize(books_data.review)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "vocab = set([word for sent in X_tokenized for word in sent])\n",
    "word_index = {}\n",
    "index = 1\n",
    "for word in vocab:\n",
    "    word_index[word] = index\n",
    "    index += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_indexed = [[word_index[word] for word in sent] for sent in X_tokenized]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_padded = preprocessing.nn_pad(X_indexed, None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y_one_hot = preprocessing.one_hot_encode(books_data.score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_one_hot, y_test_one_hot = train_test_split(X_padded, y_one_hot, test_size=0.20,\n",
    "                                                                    random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "embeddings_matrix = preprocessing.create_embeddings_matrix(word_index)\n",
    "input_length = len(X_padded[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def tcn_model(input_length, emb_matrix):\n",
    "    inp = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=embeddings_matrix.shape[0],\n",
    "                  output_dim=embeddings_matrix.shape[1],\n",
    "                  input_length=input_length,\n",
    "                  # Assign the embedding weight with word2vec embedding marix\n",
    "                  weights=[emb_matrix],\n",
    "                  # Set the weight to be not trainable (static)\n",
    "                  trainable=False)(inp)\n",
    "\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = TCN(128, dilations=[1, 2, 4], return_sequences=True, activation='relu', name='tcn1')(x)\n",
    "    x = TCN(64, dilations=[1, 2, 4], return_sequences=True, activation='relu', name='tcn2')(x)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    conc = Dense(16, activation=\"relu\")(conc)\n",
    "    conc = Dropout(0.1)(conc)\n",
    "    outp = Dense(5, activation=\"softmax\")(conc)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 724)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 724, 300)     4985400     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " spatial_dropout1d (SpatialDrop  (None, 724, 300)    0           ['embedding[0][0]']              \n",
      " out1D)                                                                                           \n",
      "                                                                                                  \n",
      " tcn1 (TCN)                     (None, 724, 128)     400256      ['spatial_dropout1d[0][0]']      \n",
      "                                                                                                  \n",
      " tcn2 (TCN)                     (None, 724, 64)      94656       ['tcn1[0][0]']                   \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 64)          0           ['tcn2[0][0]']                   \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 64)          0           ['tcn2[0][0]']                   \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 , 'global_max_pooling1d[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           2064        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 16)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 5)            85          ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,482,461\n",
      "Trainable params: 497,061\n",
      "Non-trainable params: 4,985,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "deep_model = tcn_model(input_length, embeddings_matrix)\n",
    "print(deep_model.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1/1 [==============================] - 63s 63s/step - loss: 6.6220 - accuracy: 0.1984 - val_loss: 2.2815 - val_accuracy: 0.2062\n",
      "Epoch 2/8\n",
      "1/1 [==============================] - 46s 46s/step - loss: 2.4991 - accuracy: 0.1875 - val_loss: 1.9082 - val_accuracy: 0.2313\n",
      "Epoch 3/8\n",
      "1/1 [==============================] - 36s 36s/step - loss: 2.0995 - accuracy: 0.1922 - val_loss: 1.6648 - val_accuracy: 0.2688\n",
      "Epoch 4/8\n",
      "1/1 [==============================] - 39s 39s/step - loss: 1.7478 - accuracy: 0.1922 - val_loss: 1.6552 - val_accuracy: 0.2062\n",
      "Epoch 5/8\n",
      "1/1 [==============================] - 48s 48s/step - loss: 1.6624 - accuracy: 0.1953 - val_loss: 1.6239 - val_accuracy: 0.2250\n",
      "Epoch 6/8\n",
      "1/1 [==============================] - 35s 35s/step - loss: 1.6141 - accuracy: 0.2422 - val_loss: 1.6073 - val_accuracy: 0.1875\n",
      "Epoch 7/8\n",
      "1/1 [==============================] - 32s 32s/step - loss: 1.6141 - accuracy: 0.2016 - val_loss: 1.6090 - val_accuracy: 0.2125\n",
      "Epoch 8/8\n",
      "1/1 [==============================] - 36s 36s/step - loss: 1.6108 - accuracy: 0.2047 - val_loss: 1.6093 - val_accuracy: 0.2062\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 8\n",
    "\n",
    "history = deep_model.fit(X_train, y_train_one_hot, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MSE: 6.865\n",
      "Accuracy: 0.185\n"
     ]
    }
   ],
   "source": [
    "predictions_one_hot = deep_model.predict(X_test)\n",
    "predictions = [list(one_hot).index(max(one_hot)) + 1 for one_hot in predictions_one_hot]\n",
    "y_test = [list(one_hot).index(max(one_hot)) + 1 for one_hot in y_test_one_hot]\n",
    "print(\"     MSE:\", mean_squared_error(y_test, predictions))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def get_nn_classifier(embeddings_matrix, input_length):\n",
    "    model = Sequential()\n",
    "\n",
    "    embedding_layer = Embedding(\n",
    "        embeddings_matrix.shape[0],\n",
    "        embeddings_matrix.shape[1],\n",
    "        weights=[embeddings_matrix],\n",
    "        input_length=input_length,\n",
    "        trainable=False\n",
    "    )\n",
    "    model.add(embedding_layer)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 2117, 300)         29217300  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 635100)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 635100)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                20323232  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,541,753\n",
      "Trainable params: 20,324,453\n",
      "Non-trainable params: 29,217,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_nn_classifier(embeddings_matrix, input_length)\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "13/13 [==============================] - 314s 22s/step - loss: 1.5878 - accuracy: 0.2621 - val_loss: 1.5333 - val_accuracy: 0.3206\n",
      "Epoch 2/8\n",
      "13/13 [==============================] - 224s 17s/step - loss: 1.3910 - accuracy: 0.4032 - val_loss: 1.4888 - val_accuracy: 0.3494\n",
      "Epoch 3/8\n",
      " 9/13 [===================>..........] - ETA: 1:31:08 - loss: 1.2091 - accuracy: 0.5052"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 8\n",
    "\n",
    "history = model.fit(X_train, y_train_one_hot, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MSE: 2.32525\n",
      "Accuracy: 0.3505\n"
     ]
    }
   ],
   "source": [
    "predictions_one_hot = model.predict(X_test)\n",
    "predictions = [list(one_hot).index(max(one_hot)) + 1 for one_hot in predictions_one_hot]\n",
    "y_test = [list(one_hot).index(max(one_hot)) + 1 for one_hot in y_test_one_hot]\n",
    "print(\"     MSE:\", mean_squared_error(y_test, predictions))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, books_data.score, test_size=0.20, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 2117, 300)         29217300  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 635100)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                20323232  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49,541,621\n",
      "Trainable params: 20,324,321\n",
      "Non-trainable params: 29,217,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = preprocessing.get_nn_linear(embeddings_matrix, input_length)\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "13/13 [==============================] - 46s 3s/step - loss: 3.5329 - val_loss: 1.9403\n",
      "Epoch 2/8\n",
      "13/13 [==============================] - 32s 2s/step - loss: 2.2718 - val_loss: 1.7023\n",
      "Epoch 3/8\n",
      "13/13 [==============================] - 31s 2s/step - loss: 2.0723 - val_loss: 1.6369\n",
      "Epoch 4/8\n",
      "13/13 [==============================] - 31s 2s/step - loss: 1.0471 - val_loss: 1.6263\n",
      "Epoch 5/8\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.7494 - val_loss: 1.6273\n",
      "Epoch 6/8\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.5884 - val_loss: 1.6530\n",
      "Epoch 7/8\n",
      "13/13 [==============================] - 32s 2s/step - loss: 0.4669 - val_loss: 1.7128\n",
      "Epoch 8/8\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.3795 - val_loss: 1.7406\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 8\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MSE: 1.85025\n",
      "     MSE: 1.8034910509345174\n",
      "Accuracy: 0.29225\n"
     ]
    }
   ],
   "source": [
    "predictions_decimal = model.predict(X_test)\n",
    "predictions = [max(min(round(prediction[0]), 5), 1) for prediction in predictions_decimal]\n",
    "print(\"     MSE:\", mean_squared_error(y_test, predictions))\n",
    "print(\"     MSE:\", mean_squared_error(y_test, predictions_decimal))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a grouped bar chart, with job as the x-axis\n",
    "# and gender as the variable we're grouping on so there\n",
    "# are two bars per job.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Our x-axis. We basically just want a list\n",
    "# of numbers from zero with a value for each\n",
    "# of our jobs.\n",
    "xs = np.arange(2)\n",
    "\n",
    "# Define bar width. We need this to offset the second bar.\n",
    "bar_width = 0.4\n",
    "\n",
    "b1 = ax.bar(xs, [0.55, 0.39], width=bar_width, label='Naive Bayes')\n",
    "# Same thing, but offset the x.\n",
    "b2 = ax.bar(xs + bar_width, [0.56, 0.33], width=bar_width, label='Neural Network')\n",
    "\n",
    "# Fix the x-axes.\n",
    "ax.set_xticks(xs + bar_width / 2)\n",
    "ax.set_xticklabels([\"Unbalanced\", \"Balanced\"])\n",
    "\n",
    "# Add legend.\n",
    "ax.legend()\n",
    "\n",
    "# Axis styling.\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_color('#DDDDDD')\n",
    "ax.tick_params(bottom=False, left=False)\n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(True, color='#EEEEEE')\n",
    "ax.xaxis.grid(False)\n",
    "\n",
    "# Add axis and chart labels.\n",
    "ax.set_ylabel('Accuracy', labelpad=15)\n",
    "ax.set_title('Model accuracies', pad=15)\n",
    "\n",
    "fig.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
